{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCzsCyw5IYGq"
   },
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQK7-NbRg1nx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "# import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.is_gpu_available()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEE80gJVI101"
   },
   "source": [
    "# Retrieve images and masks from file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwT-gHmrtp4E"
   },
   "outputs": [],
   "source": [
    "#Get file paths\n",
    "\n",
    "image_dir = '../data/feb-25/train/images/'\n",
    "mask_dir = '../data/feb-25/train/masks/'\n",
    "\n",
    "image_paths = glob.glob(image_dir+\"*.jpg\")\n",
    "mask_paths = glob.glob(mask_dir+\"*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Images: {len(image_paths)}')\n",
    "print(f'Masks: {len(mask_paths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Tp1bWF642Ug"
   },
   "outputs": [],
   "source": [
    "# # Train test validation split function\n",
    "# def get_train_and_validation_splits(img_paths, mask_paths):\n",
    "#     img_paths.sort()\n",
    "#     mask_paths.sort()\n",
    "    \n",
    "#     train_img_paths, temp_img_paths, train_mask_paths, temp_mask_paths = train_test_split(image_paths, mask_paths, \n",
    "#                                                                           train_size=0.7, random_state=711)\n",
    "    \n",
    "# #     print(len(temp_img_paths))\n",
    "\n",
    "#     val_img_paths, test_img_paths, val_mask_paths,  test_mask_paths = train_test_split(temp_img_paths, temp_mask_paths,\n",
    "#                                                                                      test_size=0.4)\n",
    "\n",
    "#     return train_img_paths, train_mask_paths, val_img_paths, val_mask_paths, test_img_paths, test_mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test validation split function\n",
    "def get_train_and_validation_splits(img_paths, mask_paths):\n",
    "    img_paths.sort()\n",
    "    mask_paths.sort()\n",
    "    \n",
    "    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(image_paths, mask_paths, \n",
    "                                                                          test_size=0.25, random_state=711)\n",
    "    \n",
    "\n",
    "    return train_img_paths, train_mask_paths, val_img_paths, val_mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sorted(glob.glob('../data/feb-25/test/images/*.jpg'))\n",
    "Y_test = sorted(glob.glob('../data/feb-25/test/masks/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIxS4arr6M9n"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, = get_train_and_validation_splits(image_paths, mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train: {len(X_train)} \\nTest: {len(X_test)} \\nVal: {len(X_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc_JqgQHXJM_"
   },
   "source": [
    "# Define helper functions for loading, preprocessing and displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_KueJitXJNH"
   },
   "outputs": [],
   "source": [
    "#Map class values to class names\n",
    "classes = {0:'damage', \n",
    "           1:'corm', \n",
    "           2:'background'}\n",
    "\n",
    "#Map pixel values to class values\n",
    "pixel_map = {(0,0,0):[2], \n",
    "             (0,255,0):[1], \n",
    "             (255,0,0):[0]}\n",
    "\n",
    "#Map class values to pixel values\n",
    "class_map = {2:[0,0,0], \n",
    "             1:[0,255,0], \n",
    "             0:[255,0,0]}\n",
    "\n",
    "image_shape = (512,512,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    'image_size': str(image_shape[0]),\n",
    "    'train_samples': len(X_train),\n",
    "    'val_samples': len(X_val),\n",
    "    'test_samples': len(X_test),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-oFepo4QXJND"
   },
   "outputs": [],
   "source": [
    "def random_rotation(img, mask):\n",
    "    '''\n",
    "    Randomly rotates images 90 degrees anticlockwise\n",
    "    '''\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = tf.image.rot90(img)\n",
    "        mask = tf.image.rot90(mask)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(img, mask):\n",
    "    '''\n",
    "    Randomly flips images horizontally (left to right)\n",
    "    '''\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gaussian_blur(img):\n",
    "    '''\n",
    "    Applies a gaussian blur to images\n",
    "    '''\n",
    "    img = tfa.image.gaussian_filter2d(img, padding='CONSTANT')\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(img, mask):\n",
    "    '''\n",
    "    Shifts images in random directions by a random factor\n",
    "    '''\n",
    "    img_shape = img.shape\n",
    "    mask_shape = mask.shape\n",
    "\n",
    "    #Create translation vector\n",
    "    tx = tf.random.uniform((), minval=-15, maxval=15)\n",
    "    ty = tf.random.uniform((), minval=-15, maxval=15)\n",
    "\n",
    "    img = tfa.image.translate(img, [tx,ty])\n",
    "    mask = tfa.image.translate(mask, [tx,ty], fill_value=2)\n",
    "\n",
    "    #Enforce shape consistency\n",
    "    img.set_shape(img_shape)\n",
    "    mask.set_shape(mask_shape)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_injection(img, im_shape=image_shape):\n",
    "    '''\n",
    "    Adds noise to images by a random factor\n",
    "    '''\n",
    "    #Get random noise factor\n",
    "    noise_factor = tf.random.uniform((), maxval=0.1)\n",
    "\n",
    "    #Generate noise from a gaussian distribution by a random factor\n",
    "    noise = noise_factor * tf.random.normal(shape=im_shape)\n",
    "\n",
    "    #Create noisy image\n",
    "    noisy_img = noise + img\n",
    "\n",
    "    #Enforce pixel range consistency\n",
    "    noisy_img = tf.clip_by_value(noisy_img, 0.0, 1.0)\n",
    "\n",
    "    return noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_transformations(img, mask):\n",
    "    '''\n",
    "    Randomly adjusts color aspects of an image\n",
    "    '''\n",
    "    img, mask = random_rotation(img, mask)\n",
    "    img, mask = random_flip(img, mask)\n",
    "\n",
    "    img = tf.image.random_brightness(img, 0.4)\n",
    "    img = tf.image.random_contrast(img, 0.5, 2.0)\n",
    "    img = tf.image.random_saturation(img, 0.75, 1.25)\n",
    "    img = tf.image.random_hue(img, 0.1)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_transformations(img, mask):\n",
    "    '''\n",
    "    Randomly adjusts positioning and orientation of an image\n",
    "    '''\n",
    "    img, mask = translate(img, mask)\n",
    "    img, mask = random_rotation(img, mask)\n",
    "    img, mask = random_flip(img, mask)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_transformations(img, mask):\n",
    "    '''\n",
    "    Randomly adds or reduces image noise\n",
    "    '''\n",
    "    img, mask = random_rotation(img, mask)\n",
    "    img, mask = random_flip(img, mask)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.3:\n",
    "        img = gaussian_blur(img)\n",
    "    else:\n",
    "        img = noise_injection(img)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_mask(mask, im_shape=image_shape):\n",
    "    '''\n",
    "    Assigns each pixel a new value with respect to it's associated class i.e.\n",
    "    reshapes masks from (w,h,3) to (w,h,1)\n",
    "      '''\n",
    "    #Get mask array\n",
    "    img_array = np.array(mask)\n",
    "\n",
    "    #Generate list of pixel sequences from mask array\n",
    "    pixels = list(Image.fromarray(img_array).getdata())\n",
    "\n",
    "    #Map pixels to classes and create new mask array\n",
    "    mask = np.array([pixel_map[px] for px in pixels])\n",
    "\n",
    "    #Reshape mask array\n",
    "    mask = np.reshape(mask, (im_shape[0],im_shape[1],1))\n",
    "\n",
    "    #Create image(mask) tensor\n",
    "    mask_tensor = tf.convert_to_tensor(mask, dtype=tf.uint8)\n",
    "\n",
    "    return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_reshape_mask(img, mask):\n",
    "    '''\n",
    "    Wrapper function to enable applying arbitrary python logic\n",
    "    '''\n",
    "    mask_shape = mask.shape\n",
    "\n",
    "    [mask,] = tf.py_function(reshape_mask, [mask], [tf.uint8])\n",
    "\n",
    "    #Enforce shape consistency\n",
    "    mask.set_shape(mask_shape)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_mask(mask, im_shape=image_shape):\n",
    "    '''\n",
    "    Reverts masks to original shape (128,128,3)\n",
    "    '''\n",
    "    #Generate list of pixel sequences from mask array\n",
    "    pixels = np.reshape(mask, (im_shape[0]*im_shape[1],1)).tolist()\n",
    "\n",
    "    #Map pixels to classes and create new mask array (with original shape)\n",
    "    mask = np.reshape(np.array([class_map[px[0]] for px in pixels], dtype='uint8'), im_shape)\n",
    "\n",
    "    #Create image(mask) tensor\n",
    "    mask_tensor = tf.convert_to_tensor(mask, dtype=tf.uint8)\n",
    "\n",
    "    return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_images_and_masks(img_path, mask_path):\n",
    "    '''\n",
    "    Loads raw images from file paths\n",
    "    '''\n",
    "    img_raw = tf.io.read_file(img_path)\n",
    "    mask_raw = tf.io.read_file(mask_path)\n",
    "    img = tf.image.decode_jpeg(img_raw)\n",
    "    mask = tf.image.decode_png(mask_raw)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, mask, size=(image_shape[0], image_shape[1])):\n",
    "    img = tf.image.resize(img, size, method='nearest')\n",
    "    mask = tf.image.resize(mask, size, method='nearest')\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(img):\n",
    "    '''\n",
    "    Normalizes images\n",
    "    '''\n",
    "    img = tf.cast(img, tf.float32)/255.0\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_train_images_and_masks(img_path, mask_path):\n",
    "    '''\n",
    "    Loads train images and masks, and performs partial preprocessing\n",
    "    '''\n",
    "    img, mask = load_raw_images_and_masks(img_path, mask_path)\n",
    "    img, mask = resize_image(img, mask)\n",
    "    img, mask = random_rotation(img, mask)\n",
    "    img, mask = random_flip(img, mask)\n",
    "    img = normalize_image(img)\n",
    "\n",
    "    return img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_images_and_masks(img_path, mask_path):\n",
    "    '''\n",
    "    Loads validation images and masks, and performs partial preprocessing\n",
    "    '''\n",
    "    img, mask = load_raw_images_and_masks(img_path, mask_path)\n",
    "    img, mask = resize_image(img, mask)\n",
    "    img = normalize_image(img)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dataset(image_paths, mask_paths):\n",
    "#     '''\n",
    "#     Generates the training dataset\n",
    "#     '''\n",
    "#     train_dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "\n",
    "#     #Apply preprocessing across the dataset\n",
    "#     train_dataset = train_dataset.map(load_train_images_and_masks, \n",
    "#                                         num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "#     return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be replaced\n",
    "def get_train_dataset(image_paths, mask_paths):\n",
    "    '''\n",
    "    Generates the training dataset\n",
    "    '''\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "\n",
    "    #Apply preprocessing across the dataset\n",
    "    train_dataset = train_dataset.map(load_train_images_and_masks, \n",
    "                                        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be replaced\n",
    "def get_validation_dataset(image_paths, mask_paths):\n",
    "    '''\n",
    "    Generates the validation dataset\n",
    "    '''\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "\n",
    "    #Apply preprocessing across the dataset\n",
    "    validation_dataset = validation_dataset.map(load_validation_images_and_masks)\n",
    "\n",
    "    return validation_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(plots, titles, cmap=None, n_examples=1, metrics=None):\n",
    "    \n",
    "    display_strings=[]\n",
    "\n",
    "    if metrics:\n",
    "        for metric in metrics:\n",
    "            display_string=''\n",
    "            for key, value in metric.items():\n",
    "                display_string += key+': '+str(value)+'\\n'\n",
    "            display_strings.append(display_string)\n",
    "\n",
    "    labels = [1,2,4,5,7,8]\n",
    "  \n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    for i in range(len(plots)):\n",
    "        ax = plt.subplot(n_examples, 3, i+1)\n",
    "        plt.title(titles[i])\n",
    "        if i in labels and metrics!=None:\n",
    "            plt.xlabel(display_strings[labels.index(i)], fontsize=12)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(plots[i], cmap=cmap)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_(plots, titles, cmap=None, n_examples=1, metrics=None, centroids=None):\n",
    "    '''\n",
    "    Displays images and associated metrics (if given)\n",
    "    '''\n",
    "    if metrics:\n",
    "        display_string='[Lesion]: [Area, Coverage(%), Distance from centroid(+)]\\n\\n'\n",
    "        for key, value in metrics.items():\n",
    "            display_string += 'Lesion'+str(key)+':  '+str(value[0])+',  '+str(value[1])+',  '+str(value[2])+'\\n'\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    for i in range(len(plots)):\n",
    "        ax = plt.subplot(n_examples, 3, i+1)\n",
    "        plt.title(titles[i])\n",
    "        if i == 0 and metrics and centroids:\n",
    "            for c in range(len(centroids[0])):\n",
    "                plt.annotate(c, centroids[0][c], color='white')\n",
    "            plt.annotate('+', centroids[1], color='white')\n",
    "            plt.xlabel(display_string, fontsize=12)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(plots[i], cmap=cmap)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_metric(name, title):\n",
    "#     '''\n",
    "#     Plots model metrics\n",
    "#     '''\n",
    "#     plt.plot(model_history.history[name], color='blue', label=name)\n",
    "#     plt.plot(model_history.history['val_'+name], color='green', label='val_'+name)\n",
    "#     plt.xlabel('epochs')\n",
    "#     plt.ylabel(name)\n",
    "#     plt.ylim(top=1)\n",
    "#     plt.title(title)\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(name, title, save_path):\n",
    "    '''\n",
    "    Plots model metrics\n",
    "    '''\n",
    "    plt.plot(model_history.history[name], color='blue', label=name)\n",
    "    plt.plot(model_history.history['val_'+name], color='green', label='val_'+name)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(name)\n",
    "    plt.ylim(top=1)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YExVz0AVNuK"
   },
   "source": [
    "# Create datasets and perform image augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOgK0PEeVnrI"
   },
   "source": [
    "Note: This process increases the size of the training set by a factor of 4 (important to remember this when determining training steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zo2gpLUdY_-R"
   },
   "outputs": [],
   "source": [
    "train = get_train_dataset(X_train, Y_train)\n",
    "val  = get_validation_dataset(X_val, Y_val)\n",
    "\n",
    "train = train.map(tf_reshape_mask)\n",
    "val = val.map(tf_reshape_mask)\n",
    "\n",
    "augmented = train.map(color_transformations)\n",
    "augmented_ = train.map(geometric_transformations)\n",
    "augmented__ = train.map(noise_transformations)\n",
    "\n",
    "train = train.concatenate(augmented)\n",
    "train = train.concatenate(augmented_)\n",
    "train = train.concatenate(augmented__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zdo11ytD_Fuh",
    "outputId": "68d45112-8b96-443e-8d24-f4c9e767f64c"
   },
   "outputs": [],
   "source": [
    "#Ensure shape consistency\n",
    "print(train.element_spec)\n",
    "print(val.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpClwCxFXlLR"
   },
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igKaGVieC_L-"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "buffer_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    'batch_size': batch_size\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYDCDETL_vq1"
   },
   "outputs": [],
   "source": [
    "#Shuffle and group into batches\n",
    "train_dataset = train.shuffle(buffer_size)\n",
    "train_dataset = train_dataset.batch(batch_size).repeat()\n",
    "\n",
    "#Prefetch to optimize processing\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "#Group into batches\n",
    "validation_dataset = val.batch(batch_size).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4maqkI197KB"
   },
   "outputs": [],
   "source": [
    "#Get samples for exploration\n",
    "samples = [(image, mask) for image, mask in train.take(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eI0mMewVFZvq"
   },
   "outputs": [],
   "source": [
    "sample_image = samples[0][0]\n",
    "sample_mask = samples[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIcgecQS7rbM",
    "outputId": "44c1c560-fa20-46a6-c09b-dd3cbab6c95e"
   },
   "outputs": [],
   "source": [
    "#Ensure shape consistency\n",
    "print(sample_image.shape)\n",
    "print(sample_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "dk7M8w9FFtrP",
    "outputId": "94ecfcf5-977e-4b9b-d483-b2f57040eafb"
   },
   "outputs": [],
   "source": [
    "#Visualize samples\n",
    "display([sample_image, sample_mask[:,:,0], revert_mask(sample_mask)], ['image','reshaped mask', 'true mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k94rENfXsR9"
   },
   "source": [
    "# Define UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpAcNJMkKM1Y"
   },
   "outputs": [],
   "source": [
    "#Import necessary tensorflow modules\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout, Input, Activation, concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "\n",
    "    # Conv2D then ReLU activation\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    # Conv2D then ReLU activation\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x, n_filters):\n",
    "    f = double_conv_block(x, n_filters)\n",
    "    p = layers.MaxPool2D(2)(f)\n",
    "    p = layers.Dropout(0.3)(p)\n",
    "\n",
    "    return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, conv_features, n_filters):\n",
    "    # upsample\n",
    "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "    # concatenate \n",
    "    x = layers.concatenate([x, conv_features])\n",
    "    # dropout\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    # Conv2D twice with ReLU activation\n",
    "    x = double_conv_block(x, n_filters)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_model(in_size=image_shape):\n",
    "\n",
    "    # inputs\n",
    "    inputs = layers.Input(shape=in_size)\n",
    "\n",
    "    # encoder: contracting path - downsample\n",
    "    # 1 - downsample\n",
    "    f1, p1 = downsample_block(inputs, 64)\n",
    "    # 2 - downsample\n",
    "    f2, p2 = downsample_block(p1, 128)\n",
    "    # 3 - downsample\n",
    "    f3, p3 = downsample_block(p2, 256)\n",
    "    # 4 - downsample\n",
    "    f4, p4 = downsample_block(p3, 512)\n",
    "\n",
    "    # 5 - bottleneck\n",
    "    bottleneck = double_conv_block(p4, 1024)\n",
    "\n",
    "    # decoder: expanding path - upsample\n",
    "    # 6 - upsample\n",
    "    u6 = upsample_block(bottleneck, f4, 512)\n",
    "    # 7 - upsample\n",
    "    u7 = upsample_block(u6, f3, 256)\n",
    "    # 8 - upsample\n",
    "    u8 = upsample_block(u7, f2, 128)\n",
    "    # 9 - upsample\n",
    "    u9 = upsample_block(u8, f1, 64)\n",
    "\n",
    "    # outputs\n",
    "    outputs = layers.Conv2D(3, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
    "\n",
    "    # unet model with Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7s8F66S4TrP0"
   },
   "outputs": [],
   "source": [
    "#Create model instance\n",
    "model = build_unet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOJkZ0gqpkku",
    "outputId": "da5d69a5-2fb3-44d8-a2b3-b28816196fd6"
   },
   "outputs": [],
   "source": [
    "#Check model summary\n",
    "model.summary()\n",
    "# keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPcXnH7yc7Ir"
   },
   "source": [
    "# Compile and build model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTy0fMWZt3g3",
    "outputId": "43640868-efc5-4225-ece0-ad8840a00201"
   },
   "outputs": [],
   "source": [
    "#Define some training parameters\n",
    "\n",
    "#Define training epochs\n",
    "epochs = 300\n",
    "\n",
    "#Define number of training examples\n",
    "n_train_examples = len(X_train)          #factor of 4 due to augmentations\n",
    "\n",
    "#Define number of validation examples\n",
    "n_val_examples = len(X_val)\n",
    "\n",
    "#Define training steps\n",
    "steps_per_epoch = n_train_examples//batch_size\n",
    "\n",
    "#Define validation steps\n",
    "val_steps = n_val_examples//batch_size\n",
    "\n",
    "wandb.log({\n",
    "    'epochs': epochs,\n",
    "    'steps_per_epoch': steps_per_epoch\n",
    "})\n",
    "\n",
    "print(f'Train exmaples: {n_train_examples}')\n",
    "print(f'Eval exmaples: {n_val_examples}')\n",
    "print(f'Steps per Epoch: {steps_per_epoch}')\n",
    "print(f'Validation steps: {val_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zu7ST712SwWY"
   },
   "outputs": [],
   "source": [
    "#Define custom training metric\n",
    "\n",
    "def dice_coeff(true_mask, pred_mask):\n",
    "    '''\n",
    "    Defines the training metric i.e. \n",
    "    calculates the dice coefficient for the necrosis class\n",
    "    '''\n",
    "    #Enforce shape consistency\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "\n",
    "    #Avoid zero division\n",
    "    smoothing_factor = 0.000001\n",
    "\n",
    "    intersection = tf.reduce_sum(tf.cast((pred_mask == 0), tf.float32) * tf.cast((true_mask == 0), tf.float32))\n",
    "    pred_area = tf.reduce_sum(tf.cast((pred_mask == 0), tf.float32))\n",
    "    true_area = tf.reduce_sum(tf.cast((true_mask == 0), tf.float32))\n",
    "    combined_area = pred_area + true_area\n",
    "\n",
    "    score = 2 * ((intersection + smoothing_factor) / (combined_area + smoothing_factor))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vkxQarct3d6"
   },
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=[dice_coeff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create results directory\n",
    "training_dir = f'unet-training/{datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")}/'\n",
    "os.makedirs(training_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'unet-training/{datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'corm_experiments'\n",
    "wandb.init(project=proj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyzX5W27t3cP",
    "outputId": "c0e04920-ae07-4dca-8ce4-72b0b88088dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build model\n",
    "model_history = model.fit(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          epochs=epochs, \n",
    "                          validation_data=validation_dataset, \n",
    "                          steps_per_epoch=steps_per_epoch, \n",
    "                          validation_steps=val_steps, \n",
    "                          callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_dice_coeff', \n",
    "                                                                      mode='max', \n",
    "                                                                      patience=100),\n",
    "                                     tf.keras.callbacks.ModelCheckpoint(f'{training_dir}model_feb25_epoch-{epochs:02d}_{datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")}.h5', \n",
    "                                                                        save_best_only=True, \n",
    "                                                                        save_weights_only=True),\n",
    "                                    WandbMetricsLogger()]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "hist_df = pd.DataFrame(model_history.history) \n",
    "hist_df.to_csv(f'{training_dir}history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "iV8I7fVNYsqJ",
    "outputId": "4e9d1902-4f48-46bb-8b7b-8b89b6ce24b5"
   },
   "outputs": [],
   "source": [
    "#Plot model metrics\n",
    "plot_metric('loss', 'Training loss vs. Validation loss', f'{training_dir}loss.png')\n",
    "plot_metric('dice_coeff', 'Training dice_coeff vs. Validation dice_coeff', f'{training_dir}Dice_coeff.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DU59_HYgeFu1"
   },
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vvOgWQg-tGV"
   },
   "outputs": [],
   "source": [
    "#Evaluation utility functions\n",
    "\n",
    "def unbatch_validation_images_and_masks():\n",
    "    '''\n",
    "    Gets validation images and masks from batches\n",
    "    '''\n",
    "    #Unbatch validation dataset\n",
    "    val_dataset = validation_dataset.unbatch()\n",
    "    val_dataset = val_dataset.batch(batch_size=n_val_examples)\n",
    "\n",
    "    val_images = []\n",
    "    val_masks = []\n",
    "\n",
    "    #Get validation images and masks\n",
    "    for image, mask in val_dataset.take(1):\n",
    "        val_images = image.numpy()\n",
    "        val_masks = mask.numpy()\n",
    "\n",
    "    #Avoid 'batch size remainder' trap\n",
    "    val_images = val_images[:(n_val_examples - (n_val_examples % batch_size))]\n",
    "    val_masks = val_masks[:(n_val_examples - (n_val_examples % batch_size))]\n",
    "\n",
    "    return val_images, val_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_metrics(true_mask, pred_mask):\n",
    "    '''\n",
    "    Calculates class-wise metrics i.e.\n",
    "    intersection over union (IoU) and dice coefficient\n",
    "    '''\n",
    "    class_ious = {}\n",
    "    class_dice_scores = {}\n",
    "\n",
    "    #Avoid zero division\n",
    "    smoothing_factor = 0.000001\n",
    "\n",
    "    #Loop through classes\n",
    "    for i in range(3):\n",
    "        intersection = np.sum((pred_mask == i) * (true_mask == i))\n",
    "        pred_area = np.sum((pred_mask == i))\n",
    "        true_area = np.sum((true_mask == i))\n",
    "        combined_area = pred_area + true_area\n",
    "\n",
    "        #Calculate class IoU\n",
    "        class_ious[i] = (intersection + smoothing_factor) / (combined_area - intersection + smoothing_factor)\n",
    "\n",
    "        #Calculate class dice score\n",
    "        class_dice_scores[i] = 2 * ((intersection + smoothing_factor) / (combined_area + smoothing_factor))\n",
    "\n",
    "    return class_ious, class_dice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbarZ3OMB7Lr"
   },
   "outputs": [],
   "source": [
    "#Get validation images and masks\n",
    "val_images, val_masks = unbatch_validation_images_and_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEk7n33sjtUs",
    "outputId": "4ecf2833-05d7-46ee-b4de-4ced2ddd4ef8"
   },
   "outputs": [],
   "source": [
    "#Ensure shape consistency\n",
    "print(val_images.shape)\n",
    "print(val_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBCWb_hDq5R8"
   },
   "outputs": [],
   "source": [
    "# model.load_weights('/content/drive/MyDrive/unet weights/unet_model_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMEdclbfjhT6"
   },
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "predictions = model.predict(validation_dataset, steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHhp_KCXrpBF",
    "outputId": "eb7a7dd2-b618-4c8f-c05d-ddaee12b6011"
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuvXQk1KjkSv"
   },
   "outputs": [],
   "source": [
    "#Get overall predicted mask\n",
    "results_ = np.argmax(predictions, axis=3)\n",
    "results = results_[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QshJ2eG-rzSR",
    "outputId": "dc674cdb-5a68-49d3-d923-6de5f2442313"
   },
   "outputs": [],
   "source": [
    "print(results_.shape)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nE1TqMGiWdy"
   },
   "outputs": [],
   "source": [
    "#Get class scores\n",
    "ious, dice_scores = compute_class_metrics(val_masks, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMPBhd4buCuk",
    "outputId": "d6fa694f-fcc4-48d4-aa48-9988f7fee924"
   },
   "outputs": [],
   "source": [
    "print(classes)\n",
    "print(ious)\n",
    "print(dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\n",
    "    'eval' : {\n",
    "        'classes': classes,\n",
    "        'iou': ious,\n",
    "        'dice_scores': dice_scores\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = p.astype(np.float64) / np.max(p) # normalize the data to 0 - 1\n",
    "data = 255 * data # Now scale by 255\n",
    "img = data.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions[0]*255.0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions[0]*255.0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jmWro_VVJW1"
   },
   "source": [
    "# Post-detection analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfaP9A4RVJW2"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_damage_and_corm_masks(mask):\n",
    "  '''\n",
    "  Extracts/seperates annotations for the corm and damage lesions\n",
    "  from the segmentation mask\n",
    "  '''\n",
    "  damage_stack = []\n",
    "  corm_stack = []\n",
    "\n",
    "  #Unstack channels\n",
    "\n",
    "  #Retrieve red channel (necrosis annotation) from original mask and fill all\n",
    "  #other channels with zeros\n",
    "  necrosis_stack.append(revert_mask(mask)[:,:,0])\n",
    "  necrosis_stack.append(tf.cast(tf.fill((128,128), 0), tf.uint8))\n",
    "  necrosis_stack.append(tf.cast(tf.fill((128,128), 0), tf.uint8))\n",
    "\n",
    "  #Retrieve green channel (root annotation) from original mask and fill all\n",
    "  #other channels with zeros\n",
    "  root_stack.append(tf.cast(tf.fill((128,128), 0), tf.uint8))\n",
    "  root_stack.append(revert_mask(mask)[:,:,1])\n",
    "  root_stack.append(tf.cast(tf.fill((128,128), 0), tf.uint8))\n",
    "\n",
    "  #Restack channels and create new annotations\n",
    "  necrosis_mask = tf.stack(necrosis_stack, axis=2)\n",
    "  root_mask = tf.stack(root_stack, axis=2)\n",
    "\n",
    "  return necrosis_mask, root_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4NCEpbWVJW2"
   },
   "outputs": [],
   "source": [
    "#Post-detection utility functions\n",
    "\n",
    "def get_necrosis_and_root_masks(mask):\n",
    "  '''\n",
    "  Extracts/seperates annotations for the root and necrosis lesions\n",
    "  from the segmentation mask\n",
    "  '''\n",
    "  \n",
    "  necrosis_stack = []\n",
    "  root_stack = []\n",
    "\n",
    "  #Unstack channels\n",
    "\n",
    "  #Retrieve red channel (necrosis annotation) from original mask and fill all\n",
    "  #other channels with zeros\n",
    "  necrosis_stack.append(revert_mask(mask)[:,:,0])\n",
    "  necrosis_stack.append(tf.cast(tf.fill((128,128), 0), tf.uint8))\n",
    "  necrosis_stack.append(tf.cast(tf.fill((128,128), 0), tf.uint8))\n",
    "\n",
    "  #Retrieve green channel (root annotation) from original mask and fill all\n",
    "  #other channels with zeros\n",
    "  root_stack.append(tf.cast(tf.fill((128,128), 0), tf.uint8))\n",
    "  root_stack.append(revert_mask(mask)[:,:,1])\n",
    "  root_stack.append(tf.cast(tf.fill((128,128), 0), tf.uint8))\n",
    "\n",
    "  #Restack channels and create new annotations\n",
    "  necrosis_mask = tf.stack(necrosis_stack, axis=2)\n",
    "  root_mask = tf.stack(root_stack, axis=2)\n",
    "\n",
    "  return necrosis_mask, root_mask\n",
    "\n",
    "def annotate_mask(mask):\n",
    "  '''\n",
    "  Identifies contours and annotates masks with identified the contours\n",
    "  '''\n",
    "  mask_array = mask.numpy().astype(np.uint8)\n",
    "  mask_gray = cv.cvtColor(mask_array, cv.COLOR_BGR2GRAY)\n",
    "  _, mask_threshold = cv.threshold(mask_gray, 64, 128, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "  contours, hierarchies = cv.findContours(mask_threshold, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "  #Account for nested contours\n",
    "  if isinstance(hierarchies, np.ndarray):\n",
    "    parent_contours = [contour for contour, hierarchy in zip(contours, hierarchies[0].tolist()) if hierarchy[-1] == -1]\n",
    "    child_contours = [contour for contour, hierarchy in zip(contours, hierarchies[0].tolist()) if hierarchy[-1] != -1]\n",
    "    contours = [parent_contours, child_contours]\n",
    "  else:\n",
    "    contours = [contours, []]\n",
    "\n",
    "  annotated_mask = mask_array.copy()\n",
    "  annotated_mask = cv.drawContours(annotated_mask, contours[0], -1, (255,255,255), 1)\n",
    "\n",
    "  return contours, annotated_mask\n",
    "\n",
    "def cbsd_scoring(necrosis_percentage):\n",
    "  '''\n",
    "  Determines Cassava Brown Streak Disease (CBSD) score\n",
    "  with respected to the percentage of root affected by necrosis\n",
    "  '''\n",
    "  cbsd_score = 0\n",
    "\n",
    "  if necrosis_percentage <= 2:\n",
    "    cbsd_score = 1\n",
    "  elif necrosis_percentage <= 5:\n",
    "    cbsd_score = 2\n",
    "  elif necrosis_percentage <= 10:\n",
    "    cbsd_score = 3\n",
    "  elif necrosis_percentage <= 25:\n",
    "    cbsd_score = 4\n",
    "  else:\n",
    "    cbsd_score = 5\n",
    "\n",
    "  return cbsd_score\n",
    "\n",
    "def post_detection_analysis(mask):\n",
    "  '''\n",
    "  Performs post-detection analysis i.e.\n",
    "   - Identifying, counting and annotating necrosis lesions\n",
    "   - Calculating percentange of root affecting by necrosis\n",
    "   - Determining cbsd score\n",
    "   and returns results\n",
    "  '''\n",
    "  necrosis_mask, root_mask = get_necrosis_and_root_masks(mask)\n",
    "\n",
    "  necrosis_contours, necrosis_annotated_mask = annotate_mask(necrosis_mask)\n",
    "  root_contours, root_annotated_mask = annotate_mask(root_mask)\n",
    "\n",
    "  #Determine size/area of necrosis lesions (taking into account ring shaped lesions)\n",
    "  if len(necrosis_contours[1]):\n",
    "    necrosis_contour_areas = [cv.contourArea(contour) for contour in necrosis_contours[0]]\n",
    "    child_necrosis_contour_areas = [cv.contourArea(contour) for contour in necrosis_contours[1]]\n",
    "    total_necrosis_area = sum(necrosis_contour_areas) - sum(child_necrosis_contour_areas)\n",
    "  else:\n",
    "    necrosis_contour_areas = [cv.contourArea(contour) for contour in necrosis_contours[0]]\n",
    "    total_necrosis_area = sum(necrosis_contour_areas)\n",
    "\n",
    "  #Determine size/area of cassava root\n",
    "  root_contour_areas = [cv.contourArea(contour) for contour in root_contours[0]]\n",
    "  total_root_area = sum(root_contour_areas)\n",
    "\n",
    "  root_area_idx = np.argmax(root_contour_areas)\n",
    "  root_hull = cv.convexHull(root_contours[0][root_area_idx])\n",
    "  root_area_hull = cv.contourArea(root_hull)\n",
    "\n",
    "  #Account for boundary lesions/convexity defects\n",
    "  if total_necrosis_area > root_area_hull:\n",
    "    root_area_hull = total_necrosis_area + total_root_area\n",
    "\n",
    "  #Determine number of lesions\n",
    "  #and calculate percentage of root affected by necrosis\n",
    "  n_lesions = len(necrosis_contour_areas)\n",
    "  necrosis_percentage = total_necrosis_area/root_area_hull * 100\n",
    "  verdict = None\n",
    "\n",
    "  #Determine Cassava Brown Streak Disease (CBSD) score\n",
    "  cbsd_score = cbsd_scoring(necrosis_percentage)\n",
    "\n",
    "  #Determine verdict based on CBSD score\n",
    "  if cbsd_score > 1:\n",
    "    verdict = '**necrotic**'\n",
    "  else:\n",
    "    verdict = '**no necrosis**'\n",
    "\n",
    "  results = {'Number of lesions':n_lesions, \n",
    "             'Area of root':root_area_hull, \n",
    "             'Area of lesions (sum)':total_necrosis_area, \n",
    "             'Necrosis percentage':round(necrosis_percentage, 2), \n",
    "             'CBSD score':cbsd_score, \n",
    "             'Verdict':verdict}\n",
    "\n",
    "  annotated_mask = necrosis_annotated_mask + root_annotated_mask\n",
    "\n",
    "  return results, annotated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gIqJP5xFwle"
   },
   "outputs": [],
   "source": [
    "#Lesion analysis utility functions\n",
    "\n",
    "def get_thresh(mask):\n",
    "  '''\n",
    "  Performs image thresholding on masks\n",
    "  '''\n",
    "  mask_array = mask.numpy().astype(np.uint8)\n",
    "  mask_gray = cv.cvtColor(mask_array, cv.COLOR_BGR2GRAY)\n",
    "  _, mask_threshold = cv.threshold(mask_gray, 64, 128, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "  return mask_threshold\n",
    "\n",
    "def get_contours(mask):\n",
    "  '''\n",
    "  Finds and returns parent contours from mask images\n",
    "  '''\n",
    "  mask_threshold = get_thresh(mask)\n",
    "  contours, hierarchies = cv.findContours(mask_threshold, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "\n",
    "  #Account for nested contours\n",
    "  if isinstance(hierarchies, np.ndarray):\n",
    "    contours = [contour for contour, hierarchy in zip(contours, hierarchies[0].tolist()) if hierarchy[-1] == -1]\n",
    "\n",
    "  return contours\n",
    "\n",
    "def get_centroids(contours):\n",
    "  '''\n",
    "  Finds and returns centroid coordinates for\n",
    "  contours identified from mask images\n",
    "  '''\n",
    "  #Avoid zero-division error\n",
    "  smoothing_factor = 1e-10\n",
    "\n",
    "  moments = [cv.moments(cnt) for cnt in contours]\n",
    "\n",
    "  x_coords = [moment['m10'] for moment in moments]\n",
    "  y_coords = [moment['m01'] for moment in moments]\n",
    "\n",
    "  areas = [moment['m00']+smoothing_factor for moment in moments]\n",
    "\n",
    "  #Determine centroid coordinates\n",
    "  cx_coords = [x/A for x,A in zip(x_coords,areas)]\n",
    "  cy_coords = [y/A for y,A in zip(y_coords,areas)]\n",
    "\n",
    "  centroids = list(zip(cx_coords,cy_coords))\n",
    "\n",
    "  return centroids\n",
    "\n",
    "def distance_transform(mask_threshold):\n",
    "  '''\n",
    "  Applies euclidean distance transform on lesions\n",
    "  with respect to the entire root (and background)\n",
    "  '''\n",
    "  dist_trans = tfa.image.euclidean_dist_transform(mask_threshold)\n",
    "  return dist_trans\n",
    "\n",
    "def centroid_distance_transform(root, root_centroid, necrosis_thresh):\n",
    "  '''\n",
    "  Applies euclidean distance transform on lesions\n",
    "  with respect to the centre of the root\n",
    "  '''\n",
    "  #Create transform representation\n",
    "  dist_trans = np.zeros((128,128), dtype=np.uint8)\n",
    "\n",
    "  #Faintly annotate representation with root\n",
    "  cv.drawContours(dist_trans, root, -1, (4), 1)\n",
    "\n",
    "  #Get lesion pixels\n",
    "  lesion_pixels = cv.findNonZero(necrosis_thresh)[:,0].tolist()\n",
    "\n",
    "  #Calculate euclidean distance from centre of root\n",
    "  #for each pixel\n",
    "  euclidean_dist = [np.linalg.norm(px - np.array(root_centroid)) for px in lesion_pixels]\n",
    "\n",
    "  #Update representation with euclidean distances for lesion pixels\n",
    "  for px, dist in zip(lesion_pixels, euclidean_dist):\n",
    "    dist_trans[px[1], px[0]] = dist\n",
    "\n",
    "  return dist_trans\n",
    "\n",
    "def lesion_analysis(lesions, root, root_, lesion_centroids, root_centroid):\n",
    "  '''\n",
    "  Analyzes each lesion and returns associated metrics i.e.\n",
    "   - Pixel area\n",
    "   - Coverage (%)\n",
    "   - Average distance from centre of root\n",
    "\n",
    "  *Average distance from centre of root* is defined as\n",
    "  the distance between the lesion centroid and the root centroid\n",
    "  '''\n",
    "  root_area = sum([cv.contourArea(contour) for contour in root])\n",
    "  root_area_hull = cv.contourArea(root_)\n",
    "  lesion_areas = [cv.contourArea(lesion) for lesion in lesions]\n",
    "\n",
    "  #Account for edge cases/convexity defects\n",
    "  if sum(lesion_areas) > root_area_hull:\n",
    "    root_area_hull = root_area + sum(lesion_areas)\n",
    "\n",
    "  #Calculate coverage of each lesion\n",
    "  lesion_coverage_percentages = [round((lesion_area/root_area_hull)*100, 2) for lesion_area in lesion_areas]\n",
    "  \n",
    "  #Calculate average distance from centre of root\n",
    "  #for each lesion\n",
    "  dist_between_centroids = [round(np.linalg.norm(np.array(root_centroid) - np.array(lesion_centroid)), 2) for lesion_centroid in lesion_centroids]\n",
    "  \n",
    "  metrics_ = list(zip(lesion_areas, lesion_coverage_percentages, dist_between_centroids))\n",
    "\n",
    "  #Create lesion --> metrics dictionary mapping\n",
    "  metrics = {lesion_idx:metrics for lesion_idx, metrics in enumerate(metrics_)}\n",
    "\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqE2BbmGVJW4"
   },
   "outputs": [],
   "source": [
    "#Get random prediction to analyze\n",
    "idx = np.random.randint(low=0, high=n_val_examples, size=1)[0]\n",
    "\n",
    "plots = []\n",
    "metrics = []\n",
    "titles = ['Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "plots.append(val_images[idx])\n",
    "\n",
    "#Get true mask analysis results\n",
    "analysis, annotated_mask = post_detection_analysis(val_masks[idx])\n",
    "metrics.append(analysis)\n",
    "plots.append(annotated_mask)\n",
    "\n",
    "#Get predicted mask analysis results\n",
    "analysis, annotated_mask = post_detection_analysis(results[idx])\n",
    "metrics.append(analysis)\n",
    "plots.append(annotated_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qS116sIEGL-8"
   },
   "outputs": [],
   "source": [
    "#Get masks\n",
    "necrosis_mask, root_mask = get_necrosis_and_root_masks(results[idx])\n",
    "combined_mask = necrosis_mask + root_mask\n",
    "\n",
    "#Get mask thresholds\n",
    "necrosis_thresh = get_thresh(necrosis_mask)\n",
    "root_thresh = get_thresh(root_mask)\n",
    "\n",
    "#Get distance transforms\n",
    "#with respect to entire root\n",
    "necrosis_trans = distance_transform(necrosis_thresh)\n",
    "root_trans = distance_transform(root_thresh) \n",
    "combined_trans = necrosis_trans + root_trans\n",
    "\n",
    "#Get lesions and root\n",
    "lesions = get_contours(necrosis_mask)\n",
    "root = get_contours(root_mask)\n",
    "root_idx = np.argmax([cv.contourArea(contour) for contour in root])\n",
    "root_ = cv.convexHull(root[root_idx])\n",
    "\n",
    "#Get centroids\n",
    "lesion_centroids = get_centroids(lesions)\n",
    "root_centroid = get_centroids([root_])[0]\n",
    "\n",
    "#Get distance transform\n",
    "#with respect to the centre of the root\n",
    "centroid_trans = centroid_distance_transform(root, root_centroid, necrosis_thresh)\n",
    "\n",
    "plots_ = [combined_mask, centroid_trans, combined_trans]\n",
    "titles_ = ['Predicted Mask', 'Transform (w.r.t root centroid)', 'Transform (w.r.t root & background)']\n",
    "metrics_ = lesion_analysis(lesions, root, root_, lesion_centroids, root_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "v50zb23MGEOl",
    "outputId": "0aa2a36d-f276-4d1e-8aa2-54abc2ec6709"
   },
   "outputs": [],
   "source": [
    "#Visualize results\n",
    "display(plots, titles, metrics=metrics)\n",
    "display_(plots_, titles_, cmap='gray', metrics=metrics_, centroids=[lesion_centroids, root_centroid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wk922pr4EbSZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Unet_version3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "UNET",
   "language": "python",
   "name": "unet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
